<application>
  <component name="AppStorage">
    <histories>
      <item value="Look up an object with the given kwargs, updating one with defaults if it exists, otherwise create a new one. Return a tuple (object, created), where created is a boolean specifying whether an object was created." />
      <item value="If timeout is 0, then block indefinitely." />
      <item value="Source" />
      <item value="get ymip" />
      <item value="present" />
      <item value="devote" />
      <item value="贡献" />
      <item value="分类" />
      <item value="礼物" />
      <item value="prasent" />
      <item value="段落" />
      <item value="TypeError: sequence item 0: expected str instance, int found" />
      <item value="Remove first occurrence of value. Raises ValueError if the value is not presen" />
      <item value="STANDARD OPTIONS activebackground, activeforeground, anchor, background, bitmap, borderwidth, cursor, disabledforeground, font, foreground highlightbackground, highlightcolor, highlightthickness, image, justify, padx, pady, relief, repeatdelay, repeatinterval, takefocus, text, textvariable, underline, wraplength WIDGET-SPECIFIC OPTIONS command, compound, default, height, overrelief, state, width" />
      <item value="def wm_resizable(self, width=None, height=None): &quot;&quot;&quot;Instruct the window manager whether this width can be resized in WIDTH or HEIGHT. Both values are boolean values.&quot;&quot;&quot;" />
      <item value="B.isdigit() -&gt; bool Return True if all characters in B are digits and there is at least one character in B, False otherwise. &quot;&quot;&quot;" />
      <item value="automatic reloading as this is badly supported. Instead you should be using the :command:`flask` command line script's ``run`` support. .. admonition:: Keep in Mind Flask will suppress any server error w" />
      <item value="Execute a search query and get back search hits that match the query. `&lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html&gt;`_ :arg index: A list of index names to search, or a string containing a comma-separated list of index names to search; use `_all` or empty string to perform the operation on all indices :arg body: The search definition using the Query DSL :arg _source: True or false to return the _source field or not, or a list of fields to return :arg _source_exclude: A list of fields to exclude from the returned _source field :arg _source_include: A list of fields to extract and return from the _source field :arg allow_no_indices: Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes `_all` string or when no indices have been specified) :arg allow_partial_search_results: Set to false to return an overall failure if the request would produce partial results. Defaults to True, which will allow partial results in the case of timeouts or partial failures :arg analyze_wildcard: Specify whether wildcard and prefix queries should be analyzed (default: false) :arg analyzer: The analyzer to use for the query string :arg batched_reduce_size: The number of shard results that should be reduced at once on the coordinating node. This value should be used as a protection mechanism to reduce the memory overhead per search request if the potential number of shards in the request can be large., default 512 :arg ccs_minimize_roundtrips: Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution, default 'true' :arg default_operator: The default operator for query string query (AND or OR), default 'OR', valid choices are: 'AND', 'OR' :arg df: The field to use as default where no field prefix is given in the query string :arg docvalue_fields: A comma-separated list of fields to return as the docvalue representation of a field for each hit :arg expand_wildcards: Whether to expand wildcard expression to concrete indices that are open, closed or both., default 'open', valid choices are: 'open', 'closed', 'none', 'all' :arg explain: Specify whether to return detailed information about score computation as part of a hit :arg from\\_: Starting offset (default: 0) :arg ignore_unavailable: Whether specified concrete indices should be ignored when unavailable (missing or closed) :arg lenient: Specify whether format-based query failures (such as providing text to a numeric field) should be ignored :arg max_concurrent_shard_requests: The number of concurrent shard requests this search executes concurrently. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests, default 'The default grows with the number of nodes in the cluster but is at most 256.' :arg pre_filter_shard_size: A threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on it's rewrite method ie. if date filters are mandatory to match but the shard bounds and the query are disjoint., default 128 :arg preference: Specify the node or shard the operation should be performed on (default: random) :arg q: Query in the Lucene query string syntax :arg rest_total_hits_as_int: This parameter is used to restore the total hits as a number in the response. This param is added version 6.x to handle mixed cluster queries where nodes are in multiple versions (7.0 and 6.latest) :arg request_cache: Specify if request cache should be used for this request or not, defaults to index level setting :arg routing: A comma-separated list of specific routing values :arg scroll: Specify how long a consistent view of the index should be maintained for scrolled search :arg search_type: Search operation type, valid choices are: 'query_then_fetch', 'dfs_query_then_fetch' :arg size: Number of hits to return (default: 10) :arg sort: A comma-separated list of &lt;field&gt;:&lt;direction&gt; pairs :arg stats: Specific 'tag' of the request for logging and statistical purposes :arg stored_fields: A comma-separated list of stored fields to return as part of a hit :arg suggest_field: Specify which field to use for suggestions :arg suggest_mode: Specify suggest mode, default 'missing', valid choices are: 'missing', 'popular', 'always' :arg suggest_size: How many suggestions to return in response :arg suggest_text: The source text for which the suggestions should be returned :arg terminate_after: The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. :arg timeout: Explicit operation timeout :arg track_scores: Whether to calculate and return scores even if they are not used for sorting :arg track_total_hits: Indicate if the number of documents that match the query should be tracked :arg typed_keys: Specify whether aggregation and suggester names should be prefixed by their respective types in the response :arg version: Specify whether to return document version as part of a hit" />
      <item value="TypeError: search() got an unexpected keyword argument 'doc_type'" />
      <item value="Account Number Auth" />
      <item value="Account Number" />
      <item value="账号" />
      <item value="zhanghao" />
      <item value="auth" />
      <item value="user Auth" />
      <item value="verify" />
      <item value="验证" />
      <item value="直播" />
      <item value="weibo Auth" />
      <item value="认证" />
      <item value="gethostbyname ex" />
      <item value="gethostname" />
      <item value="push time" />
      <item value="Connection refused " />
      <item value="get" />
      <item value="misfire grace time" />
      <item value="too many values to unpack" />
      <item value="open() &quot;/usr/local/nginx/html/updateCategory&quot; failed (2: No such file or directory), client: 192.168.125.22, server: 192.168.129.17, request: &quot;POST /updateCategory?rowkey=7016904548-HwIyAc9lG&amp;type=weibo&amp;category=0 HTTP/1.1&quot;, host: &quot;192.168.129.17:7171&quot; " />
      <item value="report" />
      <item value="broker_version: The protocol version of the cluster being connected to. If this parameter doesn't match the actual broker version, some pykafka features may not work properly." />
      <item value="broker_version: str" />
      <item value="The protocol version of the cluster being connected to. If this parameter doesn't match the actual broker version, some pykafka features may not work properly." />
      <item value="parsing" />
      <item value="parsing_exception" />
      <item value="mapper" />
      <item value="mapper_parsing_exception" />
      <item value=" is different than the one provided" />
      <item value="EARLIEST: Indicates the earliest offset available for a partition :cvar LATEST: Indicates the latest offset available for a partition" />
      <item value="Enum for special values for earliest/latest offsets. :cvar EARLIEST: Indicates the earliest offset available for a partition :cvar LATEST: Indicates the latest offset available for a partition" />
      <item value="Offset Type" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="378" />
        <entry key="ENGLISH" value="379" />
        <entry key="GERMAN" value="1" />
        <entry key="FRENCH" value="2" />
        <entry key="HAITIAN_CREOLE" value="3" />
        <entry key="CORSICAN" value="1" />
        <entry key="ROMANIAN" value="2" />
        <entry key="SWEDISH" value="6" />
        <entry key="TELUGU" value="1" />
        <entry key="TURKISH" value="1" />
        <entry key="SPANISH" value="1" />
        <entry key="ITALIAN" value="1" />
        <entry key="HINDI" value="3" />
      </map>
    </option>
  </component>
</application>